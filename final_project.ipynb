{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split,RepeatedKFold,GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the data\n",
    "data = pd.read_csv(\"insurance[1].csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for NA vals(there are none)\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making histogram of response variable(heavily skewed)\n",
    "plt.hist(data['charges'], color = 'skyblue', bins = 15)\n",
    "plt.xlabel('Charges')\n",
    "plt.title('Distribution of Insurance Charges($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of response(also shows heavy skew)\n",
    "plt.boxplot(data['charges'])\n",
    "plt.xticks([])\n",
    "plt.ylabel('Charges')\n",
    "plt.title('Boxplot of Charges($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistic of our response variable\n",
    "data['charges'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OrdinalEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Encoding smoker, sex, and region\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmoker\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mOrdinalEncoder\u001b[49m()\u001b[38;5;241m.\u001b[39mfit_transform(data[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmoker\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmoker\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[1;32m      5\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m LabelEncoder()\u001b[38;5;241m.\u001b[39mfit_transform(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OrdinalEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "# Encoding smoker, sex, and region\n",
    "data[[\"smoker\"]] = OrdinalEncoder().fit_transform(data[[\"smoker\"]])\n",
    "print(data[\"smoker\"].value_counts())\n",
    "\n",
    "data[\"sex\"] = LabelEncoder().fit_transform(data[\"sex\"])\n",
    "print(data[\"sex\"].value_counts())\n",
    "\n",
    "data[\"region\"] = LabelEncoder().fit_transform(data[\"region\"])\n",
    "print(data[\"region\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentiles for response varaible to determine bins\n",
    "percentiles = np.percentile(data['charges'], [20, 40, 60, 80])\n",
    "print(percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually encoding response variable, creating a new one\n",
    "data['charge_class'] = data['charges'].apply(lambda x: 0 if x < 3991.5757 \n",
    "                                             else 1 if x < 7369.05 \n",
    "                                             else 2 if x < 11399.85716 \n",
    "                                             else 3 if x < 20260.626406 \n",
    "                                             else 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/tune/test split(stratifying by our response variable)\n",
    "X = data.drop(columns=['charges', 'charge_class'])\n",
    "y = data['charge_class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=13)\n",
    "X_tune, X_test, y_tune, y_test = train_test_split(X_test,y_test,  train_size = 0.50, random_state=72)\n",
    "\n",
    "# Creating kfold object for validation\n",
    "kf = RepeatedKFold(n_splits=10, n_repeats =5, random_state=10)\n",
    "\n",
    "# Using f1 score(unbalanced dataset) and balanced accuracy\n",
    "scoring = ['f1_macro','balanced_accuracy']\n",
    "#Starting with just one parameter of max depth\n",
    "param = {\"max_depth\" : [1,2,3,4,5]}\n",
    "\n",
    "cl= DecisionTreeClassifier(random_state=1000)\n",
    "# Need to figure out what's going on here\n",
    "search = GridSearchCV(cl, param, scoring=scoring, n_jobs=-1, cv=kf,refit='f1_macro')\n",
    "\n",
    "# Executing gridsearch to find best model based on parameters, printing out the model\n",
    "model = search.fit(X_train, y_train)\n",
    "best = model.best_estimator_\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of decision tree\n",
    "dot_data = export_graphviz(best, out_file=None,\n",
    "               feature_names=X.columns, # feature names from dataset\n",
    "               filled=True, \n",
    "               rounded=True, \n",
    "               class_names=['Lowest', 'Low', 'Medium', 'High', 'Highest']) # classification labels \n",
    "graph = graphviz.Source(dot_data)\n",
    "graph=graphviz.Source(dot_data)\n",
    "graph\n",
    "#graph.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable importance\n",
    "varimp=pd.DataFrame(best.feature_importances_,index = X.columns,columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(varimp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix of our tune data\n",
    "print(ConfusionMatrixDisplay.from_estimator(best,X_tune,y_tune, display_labels = ['0','1', '2', '3', '4'], colorbar=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions, classifcation report of important scores\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred_tune = best.predict(X_tune)\n",
    "y_pred_test = best.predict(X_test)\n",
    "print(\"Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_pred_test, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreating tree based on gridsearch of many parameters to see if this improves performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train/tune/test split\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcharges\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcharge_class\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcharge_class\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Train/tune/test split\n",
    "X = data.drop(columns=['charges', 'charge_class'])\n",
    "y = data['charge_class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=13)\n",
    "X_tune, X_test, y_tune, y_test = train_test_split(X_test,y_test,  train_size = 0.50, random_state=72)\n",
    "\n",
    "# Creating kfold object for validation\n",
    "kf = RepeatedKFold(n_splits=10, n_repeats =5, random_state=10)\n",
    "\n",
    "scoring = ['f1_macro','balanced_accuracy']\n",
    "param_grid = {\n",
    "    'max_depth': range(3, 8),\n",
    "    'min_samples_split': [5, 10, 15],\n",
    "    'min_samples_leaf': [2, 5, 7],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "cl= DecisionTreeClassifier(random_state=1000)\n",
    "#Set up search for best decisiontreeclassifier estimator across all of our folds based on roc_auc\n",
    "search = GridSearchCV(cl, param_grid, scoring=scoring, n_jobs=-1, cv=kf,refit='f1_macro')\n",
    "#execute search on our training data, this may take a few seconds ...\n",
    "model = search.fit(X_train, y_train)\n",
    "best = model.best_estimator_\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New confusion matrix display\n",
    "print(ConfusionMatrixDisplay.from_estimator(best,X_tune,y_tune, display_labels = ['0','1', '2', '3', '4'], colorbar=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
